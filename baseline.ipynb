{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2364 files belonging to 2 classes.\n",
      "Using 1655 files for training.\n",
      "Found 2364 files belonging to 2 classes.\n",
      "Using 709 files for validation.\n"
     ]
    }
   ],
   "source": [
    "CLASS = ('E', 'I')\n",
    "TARGET_PATH = f\"data\\\\{CLASS[0]}_{CLASS[1]}\"\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(TARGET_PATH,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    batch_size=BATCH_SIZE,\n",
    "                                                                    image_size=IMG_SIZE,\n",
    "                                                                    validation_split=0.3,\n",
    "                                                                    subset=\"training\",\n",
    "                                                                    seed=1337\n",
    "                                                                    )\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(TARGET_PATH,\n",
    "                                                                        shuffle=True,\n",
    "                                                                        batch_size=BATCH_SIZE,\n",
    "                                                                        image_size=IMG_SIZE,\n",
    "                                                                        validation_split=0.3,\n",
    "                                                                        subset=\"validation\",\n",
    "                                                                        seed=1337\n",
    "                                                                        )\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 2)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 2)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "# Rescal pixel value between [0, 255] to [-1, 1]\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1. / 127.5, offset=-1)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(acc, val_acc, loss, val_loss):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label= 'Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()), 1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3).",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b6a23a79689f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLecunNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mbase_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mIMG_SHAPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstack1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'conv5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m   return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\n\u001b[0m\u001b[0;32m    475\u001b[0m                 input_tensor, input_shape, pooling, classes, **kwargs)\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m   \u001b[1;31m# Determine proper input shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m   input_shape = imagenet_utils.obtain_input_shape(\n\u001b[0m\u001b[0;32m    152\u001b[0m       \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[0mdefault_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdefault_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         raise ValueError('When setting `include_top=True` '\n\u001b[0m\u001b[0;32m    344\u001b[0m                          \u001b[1;34m'and loading `imagenet` weights, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                          '`input_shape` should be ' + str(default_shape) + '.')\n",
      "\u001b[1;31mValueError\u001b[0m: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3)."
     ]
    }
   ],
   "source": [
    "n_input = 20\n",
    "n_hidden_1 = 20\n",
    "n_hidden_2 = 20\n",
    "n_hidden_3 = 20\n",
    "n_hidden_4 = 20\n",
    "n_hidden_5 = 20\n",
    "n_hidden_6 = 20\n",
    "n_output = 1\n",
    "\n",
    "initializer = tf.keras.initializers.LecunNormal()\n",
    "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top=True)\n",
    "base_model.trainable = False\n",
    "\n",
    "MPL_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(input_shape=(128, 1), units=n_hidden_1, activation=tf.nn.selu, name='hidden_1', kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(units=n_hidden_2, activation=tf.nn.selu, name='hidden_2', kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(units=n_hidden_3, activation=tf.nn.selu, name='hidden_3', kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(units=n_hidden_4, activation=tf.nn.selu, name='hidden_4', kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(units=n_hidden_5, activation=tf.nn.selu, name='hidden_5', kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(units=n_hidden_6, activation=tf.nn.selu, name='hidden_6', kernel_initializer=initializer),\n",
    "    tf.keras.layers.Dense(units=n_output, activation=tf.nn.selu, name='output', kernel_initializer=initializer),\n",
    "])\n",
    "\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "outputs = MPL_model(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "total_epochs=20\n",
    "model.fit(train_dataset,\n",
    "         epochs=total_epochs, # batch size?\n",
    "         validation_data=validation_dataset)\n",
    "\n",
    "print(\"HI\")\n",
    "\n",
    "# Plot training result\n",
    "\n",
    "acc = model.history['accuracy']\n",
    "val_acc = model.history['val_accuracy']\n",
    "loss = model.history['loss']\n",
    "val_loss = model.history['val_loss']\n",
    "\n",
    "plot_accuracy_loss(acc, val_acc, loss, val_loss)\n",
    "\n",
    "# Evaluation of model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)\n",
    "\n",
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}