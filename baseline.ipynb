{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('ugrp': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3c4ba6343f7992435d574cc404f0c6eba5b6be6925c810ce16fa5541083203fd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'device_lib' from 'tensorflow.python.client' (unknown location)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-54c2569e8241>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mIMG_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'device_lib' from 'tensorflow.python.client' (unknown location)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (300, 300)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 16587 files belonging to 2 classes.\n",
      "Using 11611 files for training.\n",
      "Found 16587 files belonging to 2 classes.\n",
      "Using 4976 files for validation.\n"
     ]
    }
   ],
   "source": [
    "CLASS = ('E', 'I')\n",
    "TARGET_PATH = lambda x : f\"data\\\\images\\\\{x}\\\\{CLASS[0]}_{CLASS[1]}\"\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(TARGET_PATH(\"train\"),\n",
    "                                                                    shuffle=True,\n",
    "                                                                    batch_size=BATCH_SIZE,\n",
    "                                                                    image_size=IMG_SIZE,\n",
    "                                                                    )\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(TARGET_PATH(\"test\"),\n",
    "                                                                        shuffle=True,\n",
    "                                                                        batch_size=BATCH_SIZE,\n",
    "                                                                        image_size=IMG_SIZE,\n",
    "                                                                        )\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 2)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 2)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Rescal pixel value between [0, 255] to [-1, 1]\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1. / 127.5, offset=-1)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(acc, val_acc, loss, val_loss):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label= 'Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()), 1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 397s 1s/step - loss: 0.7014 - accuracy: 0.5070 - val_loss: 0.6886 - val_accuracy: 0.5165\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6889 - accuracy: 0.5137 - val_loss: 0.6958 - val_accuracy: 0.5302\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 380s 1s/step - loss: 0.6860 - accuracy: 0.5149 - val_loss: 0.6868 - val_accuracy: 0.5343\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 380s 1s/step - loss: 0.6833 - accuracy: 0.5172 - val_loss: 0.6835 - val_accuracy: 0.5282\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 384s 1s/step - loss: 0.6808 - accuracy: 0.5228 - val_loss: 0.6829 - val_accuracy: 0.5335\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 386s 1s/step - loss: 0.6776 - accuracy: 0.5283 - val_loss: 0.7035 - val_accuracy: 0.5520\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 384s 1s/step - loss: 0.6797 - accuracy: 0.5367 - val_loss: 0.6852 - val_accuracy: 0.5472\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 384s 1s/step - loss: 0.6752 - accuracy: 0.5327 - val_loss: 0.6800 - val_accuracy: 0.5399\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 382s 1s/step - loss: 0.6681 - accuracy: 0.5443 - val_loss: 0.6849 - val_accuracy: 0.5552\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 379s 1s/step - loss: 0.6710 - accuracy: 0.5416 - val_loss: 0.6793 - val_accuracy: 0.5552\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 387s 1s/step - loss: 0.6674 - accuracy: 0.5536 - val_loss: 0.6851 - val_accuracy: 0.5581\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6667 - accuracy: 0.5532 - val_loss: 0.6749 - val_accuracy: 0.5419\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6615 - accuracy: 0.5585 - val_loss: 0.7155 - val_accuracy: 0.5681\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6641 - accuracy: 0.5665 - val_loss: 0.6802 - val_accuracy: 0.5508\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6612 - accuracy: 0.5612 - val_loss: 0.6797 - val_accuracy: 0.5621\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6585 - accuracy: 0.5698 - val_loss: 0.6794 - val_accuracy: 0.5649\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6574 - accuracy: 0.5687 - val_loss: 0.6929 - val_accuracy: 0.5657\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6574 - accuracy: 0.5741 - val_loss: 0.6770 - val_accuracy: 0.5524\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6536 - accuracy: 0.5690 - val_loss: 0.6868 - val_accuracy: 0.5661\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6560 - accuracy: 0.5753 - val_loss: 0.6819 - val_accuracy: 0.5766\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6480 - accuracy: 0.5881 - val_loss: 0.6782 - val_accuracy: 0.5649\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6448 - accuracy: 0.5838 - val_loss: 0.6745 - val_accuracy: 0.5565\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6435 - accuracy: 0.5927 - val_loss: 0.6725 - val_accuracy: 0.5702\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6434 - accuracy: 0.5869 - val_loss: 0.6795 - val_accuracy: 0.5504\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6414 - accuracy: 0.5914 - val_loss: 0.6755 - val_accuracy: 0.5488\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6405 - accuracy: 0.5906 - val_loss: 0.6884 - val_accuracy: 0.5831\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6407 - accuracy: 0.5949 - val_loss: 0.6977 - val_accuracy: 0.5790\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6499 - accuracy: 0.5926 - val_loss: 0.6747 - val_accuracy: 0.5835\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6383 - accuracy: 0.6009 - val_loss: 0.6762 - val_accuracy: 0.5831\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6348 - accuracy: 0.5977 - val_loss: 0.6966 - val_accuracy: 0.5883\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6361 - accuracy: 0.6121 - val_loss: 0.6899 - val_accuracy: 0.5927\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6318 - accuracy: 0.6086 - val_loss: 0.6857 - val_accuracy: 0.5851\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6313 - accuracy: 0.6090 - val_loss: 0.6795 - val_accuracy: 0.5677\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6292 - accuracy: 0.6123 - val_loss: 0.7028 - val_accuracy: 0.5895\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6287 - accuracy: 0.6120 - val_loss: 0.6750 - val_accuracy: 0.5778\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6262 - accuracy: 0.6114 - val_loss: 0.6873 - val_accuracy: 0.5835\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6253 - accuracy: 0.6170 - val_loss: 0.7062 - val_accuracy: 0.5883\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6297 - accuracy: 0.6208 - val_loss: 0.6761 - val_accuracy: 0.5685\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 379s 1s/step - loss: 0.6249 - accuracy: 0.6147 - val_loss: 0.6727 - val_accuracy: 0.5758\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6260 - accuracy: 0.6086 - val_loss: 0.6796 - val_accuracy: 0.5802\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6188 - accuracy: 0.6294 - val_loss: 0.7012 - val_accuracy: 0.5847\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6221 - accuracy: 0.6154 - val_loss: 0.6735 - val_accuracy: 0.5790\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6193 - accuracy: 0.6154 - val_loss: 0.6789 - val_accuracy: 0.5677\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6182 - accuracy: 0.6134 - val_loss: 0.6919 - val_accuracy: 0.5875\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6275 - accuracy: 0.6247 - val_loss: 0.6784 - val_accuracy: 0.5762\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6202 - accuracy: 0.6185 - val_loss: 0.6820 - val_accuracy: 0.5685\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6148 - accuracy: 0.6280 - val_loss: 0.7060 - val_accuracy: 0.5629\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6154 - accuracy: 0.6282 - val_loss: 0.6950 - val_accuracy: 0.5831\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6155 - accuracy: 0.6295 - val_loss: 0.6779 - val_accuracy: 0.5694\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6133 - accuracy: 0.6313 - val_loss: 0.6846 - val_accuracy: 0.5649\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6137 - accuracy: 0.6332 - val_loss: 0.6778 - val_accuracy: 0.5762\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6065 - accuracy: 0.6329 - val_loss: 0.7503 - val_accuracy: 0.5867\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6190 - accuracy: 0.6272 - val_loss: 0.6894 - val_accuracy: 0.5823\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6089 - accuracy: 0.6339 - val_loss: 0.6874 - val_accuracy: 0.5835\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6102 - accuracy: 0.6327 - val_loss: 0.7526 - val_accuracy: 0.5407\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6116 - accuracy: 0.6330 - val_loss: 0.7213 - val_accuracy: 0.5907\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6060 - accuracy: 0.6457 - val_loss: 0.6937 - val_accuracy: 0.5786\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6064 - accuracy: 0.6407 - val_loss: 0.6822 - val_accuracy: 0.5762\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6154 - accuracy: 0.6360 - val_loss: 0.7080 - val_accuracy: 0.5919\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6022 - accuracy: 0.6381 - val_loss: 0.6877 - val_accuracy: 0.5867\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6011 - accuracy: 0.6404 - val_loss: 0.6943 - val_accuracy: 0.5823\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6029 - accuracy: 0.6451 - val_loss: 0.7162 - val_accuracy: 0.5863\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6025 - accuracy: 0.6393 - val_loss: 0.7362 - val_accuracy: 0.5903\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6107 - accuracy: 0.6392 - val_loss: 0.7178 - val_accuracy: 0.5960\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6181 - accuracy: 0.6237 - val_loss: 0.6922 - val_accuracy: 0.5867\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6038 - accuracy: 0.6346 - val_loss: 0.6903 - val_accuracy: 0.5754\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5957 - accuracy: 0.6455 - val_loss: 0.8276 - val_accuracy: 0.5298\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6173 - accuracy: 0.6333 - val_loss: 0.7003 - val_accuracy: 0.5911\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5996 - accuracy: 0.6427 - val_loss: 0.7101 - val_accuracy: 0.5887\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6022 - accuracy: 0.6421 - val_loss: 0.7066 - val_accuracy: 0.5940\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6022 - accuracy: 0.6352 - val_loss: 0.6849 - val_accuracy: 0.5681\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6042 - accuracy: 0.6399 - val_loss: 0.6820 - val_accuracy: 0.5835\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5996 - accuracy: 0.6384 - val_loss: 0.6861 - val_accuracy: 0.5702\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5934 - accuracy: 0.6463 - val_loss: 0.7224 - val_accuracy: 0.5637\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.6086 - accuracy: 0.6324 - val_loss: 0.6928 - val_accuracy: 0.5923\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5963 - accuracy: 0.6440 - val_loss: 0.7206 - val_accuracy: 0.5952\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5953 - accuracy: 0.6459 - val_loss: 0.6904 - val_accuracy: 0.5694\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5968 - accuracy: 0.6441 - val_loss: 0.7389 - val_accuracy: 0.5863\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5948 - accuracy: 0.6546 - val_loss: 0.7007 - val_accuracy: 0.6004\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5908 - accuracy: 0.6482 - val_loss: 0.6978 - val_accuracy: 0.5657\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5935 - accuracy: 0.6452 - val_loss: 0.6999 - val_accuracy: 0.5714\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5989 - accuracy: 0.6414 - val_loss: 0.7023 - val_accuracy: 0.5754\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5973 - accuracy: 0.6485 - val_loss: 0.6899 - val_accuracy: 0.5903\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5907 - accuracy: 0.6447 - val_loss: 0.6957 - val_accuracy: 0.5802\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5972 - accuracy: 0.6494 - val_loss: 0.7102 - val_accuracy: 0.6060\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5964 - accuracy: 0.6489 - val_loss: 0.6839 - val_accuracy: 0.5915\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5979 - accuracy: 0.6479 - val_loss: 0.7059 - val_accuracy: 0.5645\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5944 - accuracy: 0.6476 - val_loss: 0.6859 - val_accuracy: 0.5617\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5946 - accuracy: 0.6435 - val_loss: 0.6882 - val_accuracy: 0.5948\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 378s 1s/step - loss: 0.5901 - accuracy: 0.6519 - val_loss: 0.6942 - val_accuracy: 0.5911\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5955 - accuracy: 0.6484 - val_loss: 0.7139 - val_accuracy: 0.5581\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5871 - accuracy: 0.6552 - val_loss: 0.6895 - val_accuracy: 0.5988\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.6000 - accuracy: 0.6433 - val_loss: 0.7038 - val_accuracy: 0.5806\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5928 - accuracy: 0.6532 - val_loss: 0.6910 - val_accuracy: 0.5875\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 376s 1s/step - loss: 0.5895 - accuracy: 0.6504 - val_loss: 0.7272 - val_accuracy: 0.5609\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 376s 1s/step - loss: 0.5899 - accuracy: 0.6497 - val_loss: 0.7146 - val_accuracy: 0.5621\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5864 - accuracy: 0.6518 - val_loss: 0.7214 - val_accuracy: 0.6065\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5864 - accuracy: 0.6588 - val_loss: 0.7374 - val_accuracy: 0.5923\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 376s 1s/step - loss: 0.5915 - accuracy: 0.6468 - val_loss: 0.7141 - val_accuracy: 0.5669\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 377s 1s/step - loss: 0.5819 - accuracy: 0.6606 - val_loss: 0.7826 - val_accuracy: 0.5802\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ab67f2392182>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m           validation_data=validation_dataset)\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "n_input = 20\n",
    "n_hidden_1 = 20\n",
    "n_hidden_2 = 20\n",
    "n_hidden_3 = 20\n",
    "n_hidden_4 = 20\n",
    "n_hidden_5 = 20\n",
    "n_hidden_6 = 20\n",
    "n_output = 1\n",
    "\n",
    "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "MPL_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=n_hidden_1), # dense는 activation 주로 안 씀 \n",
    "    tf.keras.layers.Dense(units=n_hidden_2),\n",
    "    tf.keras.layers.Dense(units=n_hidden_3),\n",
    "    tf.keras.layers.Dense(units=n_hidden_4),\n",
    "    tf.keras.layers.Dense(units=n_hidden_5),\n",
    "    tf.keras.layers.Dense(units=n_hidden_6),\n",
    "    tf.keras.layers.Dense(units=n_output),\n",
    "])\n",
    "\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(units = 128)(x)\n",
    "outputs = MPL_model(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), # Softmax activation function applied\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "total_epochs=20\n",
    "model.fit(train_dataset,\n",
    "          epochs=total_epochs,\n",
    "          validation_data=validation_dataset)\n",
    "\n",
    "acc = model.history['accuracy']\n",
    "val_acc = model.history['val_accuracy']\n",
    "loss = model.history['loss']\n",
    "val_loss = model.history['val_loss']\n",
    "\n",
    "plot_accuracy_loss(acc, val_acc, loss, val_loss)\n",
    "\n",
    "# Evaluation of model\n",
    "loss, accuracy = model.evaluate(test_dataset) # accuracy 는 0, 1 \n",
    "print('Test accuracy :', accuracy)\n",
    "# loss 는 확률 차이, accuracy는 0, 1차이\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}